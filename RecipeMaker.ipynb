{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10zoyvwh3VnQ"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "LE66Utxh3rFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY', 'AIzaSyBhtOUr7Mo5iKoOTPLcZoA5XhTuW16-b_I')\n",
        "gemini = genai.Client(api_key = os.environ['GOOGLE_API_KEY'])\n",
        "model = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "Md3uO6iY6G1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blue = \"#013381\"\n",
        "purple = \"#633761\"\n",
        "pink = \"#FFB8B8\"\n",
        "\n",
        "SKY =\"\\033[0;36m\"\n",
        "BLUE = \"\\033[34m\"\n",
        "RESET = \"\\033[0m\""
      ],
      "metadata": {
        "id": "PbBsAaZgIkzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r0 = \"Greet the user and ask what they plan to cook today. For example: a snack, regular meal, or dessert.\"\n",
        "call(r0)\n",
        "meal = input(\"Base: \")\n",
        "\n",
        "r1 = \"Make a passing comment about on the user's chosen meal type: \" + meal + \". Then, ask about what ingredients they have.\"\n",
        "call(r1)\n",
        "ingredients = input(\"Ingredients: \")\n",
        "\n",
        "r2 = \"Make a passing comment about on the user's available ingredients: \" + ingredients + \". Continue the questioning with what cooking appliances they own.\"\n",
        "call(r2)\n",
        "appliances = input(\"Appliance: \")\n",
        "\n",
        "r3 = \"Make a passing comment about the user's available appliances: \" + appliances + \". Now, finally ask for the recipe's desired difficulty level.\"\n",
        "call(r3)\n",
        "skill = input(\"Skill: \")\n",
        "#========\n",
        "finale = \"Brifly remind the user their recipes may take a moment to load, though the product will add be worthwhile.\"\n",
        "call(finale)\n",
        "\n",
        "recipe()\n",
        "\n",
        "parting = \"Wish the user luck with their cooking, express hopes that the recipes will be useful, and bid the user goodbye.\"\n",
        "call(parting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zk2rpSi29_t",
        "outputId": "d2ba6aec-3931-4f79-fcb2-4e6d72b48768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;36mHi there! ðŸ‘‹ What are you planning to cook up today? A quick snack, a regular meal, or maybe something sweet for dessert?\n",
            "\u001b[0m\n",
            "Base: brunch\n",
            "\u001b[0;36mAh, brunch! The socially acceptable excuse to eat pancakes at noon. ðŸ˜‰ So, what culinary treasures are you working with ingredient-wise?\n",
            "\u001b[0m\n",
            "Ingredients: turkey, paprika, pear, wine\n",
            "\u001b[0;36mOkay, turkey, paprika, pear, and wine... that sounds like the beginnings of a really interesting and potentially delicious meal! Are you thinking something sweet and savory?\n",
            "\n",
            "To help me brainstorm some specific recipes for you, what kind of cooking equipment do you have available? I'm talking things like: oven, stovetop, grill, slow cooker, Instant Pot, air fryer, etc. The more details the better!\n",
            "\u001b[0m\n",
            "Appliance: stove, microwave, food processor\n",
            "\u001b[0;36mOkay, sounds like you've got a well-equipped kitchen with the stove, microwave, and food processor at your disposal. Great! So, to tailor this recipe perfectly for you, what level of difficulty are we aiming for today: beginner, intermediate, or advanced?\n",
            "\u001b[0m\n",
            "Skill: high-intermediate\n",
            "\u001b[0;36mOkay, just a heads-up that your recipes may take a moment to load, but I promise the wait will be worthwhile! Get ready for some delicious inspiration!\n",
            "\u001b[0m\n",
            "\u001b[34mOkay, here's a brunch recipe utilizing turkey, paprika, pear, wine, and only the appliances you listed (stove, microwave, and food processor). I'll aim for something that's tasty, slightly elevated, and fun to make at a high-intermediate skill level.\n",
            "\n",
            "**Recipe: Paprika-Spiced Turkey & Pear Hash with Wine-Poached Pear Accent**\n",
            "\n",
            "**Concept:** We'll be creating a savory and slightly sweet hash with turkey as the star, seasoned with paprika for warmth. The wine-poached pear adds a touch of elegance and sweetness, and because poaching the pear is done separately, you can adjust to taste.\n",
            "\n",
            "**Yields:** 2 servings\n",
            "**Prep time:** 20 minutes\n",
            "**Cook time:** 25 minutes\n",
            "\n",
            "**Ingredients:**\n",
            "\n",
            "*   8 oz Cooked Turkey, diced into 1/2-inch pieces (leftover Thanksgiving turkey works perfectly!)\n",
            "*   1 large, firm but ripe Pear, divided (see instructions below)\n",
            "*   1/2 cup Dry White Wine (Sauvignon Blanc or Pinot Grigio work well)\n",
            "*   1 tablespoon Olive Oil\n",
            "*   1/2 medium Onion, finely diced\n",
            "*   1/2 teaspoon Sweet Paprika\n",
            "*   1/4 teaspoon Smoked Paprika (optional, but adds depth)\n",
            "*   Salt and Freshly Ground Black Pepper to taste\n",
            "*   Optional: Fresh parsley or chives, chopped, for garnish\n",
            "\n",
            "**Equipment:**\n",
            "\n",
            "*   Food Processor\n",
            "*   Microwave-safe bowl or dish\n",
            "*   Large skillet\n",
            "*   Small saucepan\n",
            "\n",
            "**Instructions:**\n",
            "\n",
            "1.  **Pear Prep:** Divide the pear. Core and dice HALF of the pear into small 1/4 inch pieces for the hash. Keep the other half whole for poaching.\n",
            "\n",
            "2.  **Wine-Poached Pear (Microwave Method):** This step can be done simultaneously with the hash to save time.\n",
            "    * Peel the remaining half of the pear. Core it carefully.\n",
            "    *   Place the pear half in a microwave-safe bowl or dish.\n",
            "    *   Pour the white wine over the pear.\n",
            "    *   Microwave on medium power for 3-5 minutes, or until the pear is tender but still holds its shape. *Note: Microwaves vary. Check doneness by inserting a fork. It should pierce easily but not be mushy. Be very careful when removing from the microwave as the steam will be very hot.*\n",
            "    *   Carefully remove the pear from the wine and set aside to cool. Save the wine! We'll use it later.\n",
            "\n",
            "3.  **Turkey Hash Base:**\n",
            "    *   In the food processor, pulse the diced pear until it resembles a coarse puree. Do not over-process!\n",
            "    *   Heat the olive oil in the large skillet over medium heat.\n",
            "    *   Add the diced onion to the skillet and sautÃ© until softened and translucent, about 5 minutes.\n",
            "    *   Add the pear puree to the skillet and cook, stirring frequently, until most of the moisture has evaporated, about 3-5 minutes. This will concentrate the pear flavor.\n",
            "\n",
            "4.  **Building the Hash:**\n",
            "    *   Add the diced turkey to the skillet with the onion and pear mixture.\n",
            "    *   Stir in the sweet paprika, smoked paprika (if using), salt, and pepper.\n",
            "    *   Cook, stirring occasionally, until the turkey is heated through and slightly browned, about 5-7 minutes.\n",
            "\n",
            "5.  **Reducing the Wine:**\n",
            "    *   Pour the wine used for poaching into the small saucepan.\n",
            "    *   Bring the wine to a simmer over medium heat and reduce it by about half, until it becomes slightly syrupy. This will intensify the wine flavor.\n",
            "\n",
            "6.  **Plating:**\n",
            "    *   Divide the turkey hash between two plates.\n",
            "    *   Slice the poached pear half and arrange the slices artfully alongside the hash.\n",
            "    *   Drizzle the reduced wine sauce over the poached pear and hash.\n",
            "    *   Garnish with chopped fresh parsley or chives, if desired.\n",
            "\n",
            "**Tips & Considerations:**\n",
            "\n",
            "*   **Turkey:** You can use leftover roasted turkey, deli turkey (though it might be saltier, so adjust seasoning), or even cooked ground turkey.\n",
            "*   **Pear Selection:** Choose a pear that is firm enough to hold its shape when cooked but ripe enough to have good flavor. Bosc or Anjou pears are good choices.\n",
            "*   **Wine Choice:** A dry white wine is best. Avoid sweet wines. The wine is primarily for poaching the pear and adds a subtle flavor nuance.\n",
            "*   **Seasoning:** Taste as you go and adjust the salt, pepper, and paprika to your liking.\n",
            "*   **Spice Level:** Paprika is not spicy, but you can add a pinch of cayenne pepper if you want a little heat.\n",
            "*   **Doneness:** Be careful not to overcook the turkey, as it can become dry.\n",
            "\n",
            "Enjoy your sophisticated and delicious brunch!\n",
            "\u001b[0m\n",
            "\u001b[0;36mOkay, best of luck with your cooking! I really hope those recipes turn out to be useful and delicious for you. Bon appÃ©tit, and goodbye for now!\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call(prompt):\n",
        "  calling = gemini.models.generate_content(\n",
        "    model=model,\n",
        "    contents=prompt,\n",
        "  )\n",
        "  print(SKY + calling.text + RESET)"
      ],
      "metadata": {
        "id": "EVfs46s3-cvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "54c0ea43-e9bb-42ba-d09c-574d84cccece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;36mHello! ðŸ‘‹  I'm here to help you figure out what to cook. What ingredients do you have on hand? Let me know and we can get started!\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:334: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://61bf122d0c93d73afc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://61bf122d0c93d73afc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recipe():\n",
        "  final = \"Please generate a \" + skill + meal + \" recipe for the user, limited to only \" + ingredients + \" for ingredients and \" + appliances + \"for appliances. Remember, the recipe cannot contain ingredients or appliances the user doesn't have. Cite your sources (if any) with links to videos or images.\"\n",
        "  finalize = gemini.models.generate_content(\n",
        "    model=model,\n",
        "    contents=final,\n",
        "\n",
        ")\n",
        "  print(BLUE + finalize.text + RESET)"
      ],
      "metadata": {
        "id": "WMujVnqsP92O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confirmation (ingredients):\n",
        "  response = input(\"Y/N: \")\n",
        "  if response == \"yes\":\n",
        "    apply = \"Ask the what appliance(s) the user has\"\n",
        "    appliance = gemini.models.generate_content(\n",
        "      model=model,\n",
        "      contents=apply,\n",
        "   )\n",
        "  if response == \"no\":\n",
        "    redo = \"Briefly apologize for making a mistake, then ask the user to re-enter their ingredients.\"\n",
        "    retry = gemini.models.generate_content(\n",
        "     model=model,\n",
        "     contents=redo,\n",
        "   )\n",
        "    print(retry.text)\n",
        "    get_data(data)\n",
        "    get_confirmation(ingredients)\n",
        "  else:\n",
        "    known = \"The input is unknown. Tell the user to try responding yes or no this time.\"\n",
        "    unknown = gemini.models.generate_content(\n",
        "     model=model,\n",
        "     contents=known,\n",
        "    )\n",
        "    print(unknown.text)\n",
        "    get_confirmation(ingredients)\n",
        "\n",
        "get_confirmation(\"ham\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "tcz26cOj2C8E",
        "outputId": "ce1157af-87f8-47df-926d-a1c2f22ef0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-257-ec90cb2ba2ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mget_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mget_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ham\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-257-ec90cb2ba2ea>\u001b[0m in \u001b[0;36mget_confirmation\u001b[0;34m(ingredients)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_confirmation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mingredients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Y/N: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mapply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Ask the what appliance(s) the user has\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     appliance = gemini.models.generate_content(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confirmation (data, time):\n",
        "  response = input(\"Y/N: \")\n",
        "  if response == \"yes\" and time == 1:\n",
        "    apply = \"Ask the what appliance(s) the user has\"\n",
        "    appliance = gemini.models.generate_content(\n",
        "      model=model,\n",
        "      contents=apply,\n",
        "   )\n",
        "  if response == \"no\":\n",
        "    redo = \"Briefly apologize for making a mistake, then ask the user to re-enter their \" + data + \".\"\n",
        "    retry = gemini.models.generate_content(\n",
        "     model=model,\n",
        "     contents=redo,\n",
        "   )\n",
        "    print(retry.text)\n",
        "    get_data(data)\n",
        "    get_confirmation(data, time)\n",
        "  else:\n",
        "    known = \"The input is unknown. Tell the user to try responding yes or no this time.\"\n",
        "    unknown = gemini.models.generate_content(\n",
        "     model=model,\n",
        "     contents=known,\n",
        "    )\n",
        "    print(unknown.text)\n",
        "    get_confirmation(data, time)"
      ],
      "metadata": {
        "id": "iYv3mbSOy9jt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}